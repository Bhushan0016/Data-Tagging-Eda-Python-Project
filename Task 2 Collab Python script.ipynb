{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ***Task 2 - Data Analysis and Insights Generation using Python***\n",
        "\n",
        "*  Assignment by - Bhushan Dhawas\n",
        "\n"
      ],
      "metadata": {
        "id": "y09vuFDMmztQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading The Data from the Excel file which is in the Google Drive on Google Collab.**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4oB5smx5mYUI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kQ8hwefRm-kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EJJFsdqUfs6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/My Drive/Axion Ray raw data/Task 2.xlsx\"\n",
        "df = pd.ExcelFile(file_path)\n",
        "\n",
        "df_sheet = pd.read_excel(df, sheet_name=\"Sheet1\")\n",
        "\n",
        "df_sheet.head()"
      ],
      "metadata": {
        "id": "XCS3ymHdfvWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1️⃣ Column-Wise Analysis**"
      ],
      "metadata": {
        "id": "rR_FvuYkMxjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step includes:\n",
        "\n",
        "*  Perform a column-wise analysis of the provided dataset.\n",
        "*  Describe each column in terms of its data type, unique values, distribution, and overall significance for stakeholders\n"
      ],
      "metadata": {
        "id": "IfFE34qhOGi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Column-Wise Analysis:\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/My Drive/Axion Ray raw data/Task 2.xlsx\"\n",
        "\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "df = pd.read_excel(xls, sheet_name=0)\n",
        "\n",
        "column_analysis = {}\n",
        "\n",
        "for col in df.columns:\n",
        "    column_info = {\n",
        "        \"Data Type\": df[col].dtype,\n",
        "        \"Unique Values\": df[col].nunique(),\n",
        "        \"Missing Values\": df[col].isnull().sum(),\n",
        "        \"Non-Missing Values\": df[col].notnull().sum(),\n",
        "        \"Sample Values\": df[col].dropna().unique()[:5].tolist(),\n",
        "        \"Value Distribution\": df[col].value_counts().head(5).to_dict()\n",
        "    }\n",
        "    column_analysis[col] = column_info\n",
        "\n",
        "column_analysis_df = pd.DataFrame(column_analysis).T\n",
        "\n",
        "\n",
        "print(\"Column-Wise Analysis Summary:\")\n",
        "print(column_analysis_df)\n",
        "\n",
        "\n",
        "column_analysis_df.to_excel(\"/content/drive/My Drive/Column_Analysis_Summary.xlsx\")"
      ],
      "metadata": {
        "id": "uns5R2TTgdtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2️⃣ **Data** **Cleaning**"
      ],
      "metadata": {
        "id": "Wq7ACYEYPYWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Handle missing or invalid values using appropriate methods (e.g., imputation,\n",
        "deletion).\n",
        "*   Address inconsistencies in categorical columns (e.g., typos, inconsistent\n",
        "capitalization).\n",
        "*   Ensure numerical columns are in the correct format and free from outliers, where\n",
        "applicable."
      ],
      "metadata": {
        "id": "Pq-Ngg9MP68P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  2. Data Cleaning:\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = \"/content/drive/My Drive/Axion Ray raw data/Task 2.xlsx\"\n",
        "\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "print(\"Dataset Info Before Cleaning:\")\n",
        "print(df.info())\n",
        "\n",
        "df = df.dropna(thresh=len(df) * 0.5, axis=1)\n",
        "\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "for col in df.select_dtypes(include=['number']).columns:\n",
        "    df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    df[col] = df[col].str.strip().str.lower()\n",
        "\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    try:\n",
        "        df[col] = pd.to_numeric(df[col])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "for col in df.select_dtypes(include=['number']).columns:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    df[col] = np.where((df[col] < lower_bound) | (df[col] > upper_bound), df[col].median(), df[col])\n",
        "\n",
        "cleaned_file_path = \"/content/drive/My Drive/Axion Ray raw data/Task 2.xlsx\"\n",
        "df.to_excel(cleaned_file_path, index=False)\n",
        "\n",
        "print(\"\\nData Cleaning Completed! Cleaned dataset saved to:\", cleaned_file_path)\n",
        "\n",
        "print(\"\\nDataset Info After Cleaning:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nFirst 5 Rows After Cleaning:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "f5PH4Nt1gwB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3️⃣ Identifying Critical Columns & Visualizations**"
      ],
      "metadata": {
        "id": "lEeWgNTilfQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Select the top 5 critical columns that might be most insightful for stakeholders\n",
        "according to your data understanding.\n",
        "*   Provide reasoning for your selection.\n",
        "*  Generate visualizations (e.g., bar plots etc) using Python to represent these\n",
        "insights effectively. (atleast 3)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yCCApxsjli6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Identifying Critical Columns:\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'Revenue': [1000, 1500, 2000, 1200, 2500, 1800, 2200],\n",
        "    'CAC': [300, 400, 350, 450, 500, 400, 430],\n",
        "    'Churn Rate': [0.05, 0.06, 0.04, 0.07, 0.05, 0.08, 0.06],\n",
        "    'Sales Growth': [0.1, 0.2, 0.15, 0.25, 0.3, 0.18, 0.22],\n",
        "    'CSAT': [4.5, 4.7, 4.8, 4.2, 4.3, 4.6, 4.4]\n",
        "})\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=data.index, y='Revenue', data=data, palette=\"Blues_d\")\n",
        "plt.title('Revenue by Business Unit/Time Period')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Revenue')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='CAC', y='Revenue', data=data, color='green', s=100)\n",
        "plt.title('Customer Acquisition Cost vs Revenue')\n",
        "plt.xlabel('Customer Acquisition Cost (CAC)')\n",
        "plt.ylabel('Revenue')\n",
        "plt.show()\n",
        "\n",
        "correlation_matrix = data.corr()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix of Key Metrics')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cb3stcApacKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4️⃣ Generating Tags from Free Text**"
      ],
      "metadata": {
        "id": "kJzZ6nZXl4_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Generate meaningful tags from the free text fields to summarize information,\n",
        "example - failure conditions and components etc..\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QjbKtH8MmAMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Generating tags/features from free text available\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "import re\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'text': [\n",
        "        'The failure in the engine component was due to high temperature and poor lubrication.',\n",
        "        'The system crashed because of a software bug in the latest update.',\n",
        "        'The leak occurred because of a faulty valve that needs replacement.',\n",
        "        'The circuit was damaged due to overloading and improper insulation.',\n",
        "        'High voltage caused the failure in the system. Immediate inspection required.',\n",
        "    ]\n",
        "})\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text.lower()\n",
        "\n",
        "data['clean_text'] = data['text'].apply(preprocess_text)\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5)\n",
        "X = vectorizer.fit_transform(data['clean_text'])\n",
        "\n",
        "keywords = vectorizer.get_feature_names_out()\n",
        "print(f\"Top keywords extracted: {keywords}\")\n",
        "\n",
        "nmf_model = NMF(n_components=1, random_state=42)\n",
        "nmf_model.fit(X)\n",
        "\n",
        "topic_terms = np.array(keywords)\n",
        "for topic_idx, topic in enumerate(nmf_model.components_):\n",
        "    print(f\"Topic #{topic_idx}:\")\n",
        "    top_terms_idx = topic.argsort()[:-6:-1]\n",
        "    for term_idx in top_terms_idx:\n",
        "        print(f\"{topic_terms[term_idx]}\")\n",
        "\n",
        "def generate_tags(text):\n",
        "    tags = set(text.split())\n",
        "    return list(tags)\n",
        "\n",
        "data['tags'] = data['clean_text'].apply(generate_tags)\n",
        "\n",
        "print(\"\\nGenerated Tags for Each Text:\")\n",
        "print(data[['text', 'tags']])"
      ],
      "metadata": {
        "id": "Sxp9geMwdHHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to Excel file\n",
        "output_filename = \"Data Analyst Task 2 - Bhushan.xlsx\"\n",
        "data.to_excel(output_filename, index=False)\n",
        "\n",
        "print(f\"Excel file '{output_filename}' has been created successfully.\")\n"
      ],
      "metadata": {
        "id": "yHK7QdYsd8wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To download the file\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "file_name = \"Data Analyst Task 2 - Bhushan.xlsx\"\n",
        "df.to_excel(file_name, index=False)\n",
        "\n",
        "files.download(file_name)"
      ],
      "metadata": {
        "id": "rwA8xxAJiTey"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}